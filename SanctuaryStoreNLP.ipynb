{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import nltk.data\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import defaultdict, Counter\n",
    "import string\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('SanctuaryStore.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "contents = Path(\"./SanctuaryStore.txt\").read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes_dict = defaultdict(list)\n",
    "data = open('SanctuaryStore.txt')\n",
    "n=0\n",
    "for block in data:\n",
    "    n+=1\n",
    "    #print (block)\n",
    "    #print(len(block))\n",
    "    if len(block) < 3:\n",
    "        continue\n",
    "    block_split = block.split(sep=\":\")\n",
    "   # print (type(block_split))\n",
    "    #print (\"name:\",block_split[0])\n",
    "    #print(\"said:\",block_split[1])\n",
    "    minutes_dict[block_split[0]].append(block_split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (minutes_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minutes_dict['Casey']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_dict = defaultdict(list)\n",
    "header = open('SanctuaryStoreHeader.txt')\n",
    "for block in header:\n",
    "    print(block)\n",
    "    '''for b in block:\n",
    "        print (b)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_dict = defaultdict(list)\n",
    "attendance_list = []\n",
    "attendance = open('attendance.txt')\n",
    "\n",
    "for block in attendance:\n",
    "    #print(block)\n",
    "    name=block.split()\n",
    "    if not name:\n",
    "        continue\n",
    "    attendance_dict[name[0]]\n",
    "    attendance_list.append(name[0])\n",
    "    '''for b in block:\n",
    "        print (b)'''\n",
    "attendance_dict\n",
    "attendance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wage=40.45\n",
    "length_of_meeting=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_dict=Counter()\n",
    "total = 0\n",
    "for speaker in minutes_dict.keys():\n",
    "    print (speaker,len(minutes_dict[speaker]))\n",
    "    for speeches in range(len(minutes_dict[speaker])):\n",
    "        print (speaker,speeches,minutes_dict[speaker][speeches])\n",
    "        print(len(minutes_dict[speaker][speeches]))\n",
    "        word_count_dict[speaker]+=len(minutes_dict[speaker][speeches])\n",
    "        total+=len(minutes_dict[speaker][speeches])\n",
    "word_count_dict['Total']+=total\n",
    "word_count_dict\n",
    "df_word_counts="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_counts=pd.DataFrame.from_dict(word_count_dict,orient='index',columns=['Word Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_counts['Percentage']=df_word_counts['Word Count']/df_word_counts['Word Count']['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_counts['Cost'] = df_word_counts['Percentage']*len(attendance_list)*wage*length_of_meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_counts_no_total = df_word_counts.drop('Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_word_counts_no_total.index\n",
    "x = df_word_counts_no_total['Word Count']\n",
    "label_amount=df_word_counts_no_total['Cost']\n",
    "\n",
    "plt.barh(df_word_counts_no_total.index,width=df_word_counts_no_total['Word Count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot(y,x,label_amount):\n",
    "    \n",
    "    x = [r for r in x]\n",
    "    y = [r for r in y]\n",
    "\n",
    "    fig, ax = plt.subplots()    \n",
    "    width = 0.75 # the width of the bars \n",
    "    ind = np.arange(len(y))  # the x locations for the groups\n",
    "    ax.barh(x, y, width, color=\"green\")\n",
    "    ax.set_yticks(x)\n",
    "    #ax.set_yticklabels(x, minor=False)\n",
    "    plt.title(\"Value of Words\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')     \n",
    "    for i, v in x:\n",
    "        ax.text(v, i-.25, str(label_amount[v]), color='blue', fontweight='bold')\n",
    "    plt.pause(0.00001)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plot(y,x,label_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speaker_dictionary_maker(speaker):\n",
    "    speaker_dict = defaultdict(int)\n",
    "    for statements in minutes_dict[speaker]:\n",
    "        #print (statements)\n",
    "        #print (type(statements))\n",
    "        statements = statements.translate(str.maketrans('', '', string.punctuation))\n",
    "        for words in statements.split(\" \"):\n",
    "            word = words.strip().lower()\n",
    "            #print (word)   \n",
    "            speaker_dict[word]+=1\n",
    "    return sorted(speaker_dict.items(), key=lambda k_v: k_v[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = defaultdict(dict)\n",
    "for speaker in minutes_dict.keys():\n",
    "    speaker_dict_sorted = speaker_dictionary_maker(speaker)\n",
    "    minutes[speaker]=speaker_dict_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for block in contents:\n",
    "    n+=1\n",
    "    print (type(block))\n",
    "    print (n,block)\n",
    "    block_split = block.split(sep=\":\")\n",
    "    for b in block_split:\n",
    "        print (b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(data).toarray()\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtext = ''\n",
    "counts = defaultdict(int)\n",
    "for rows in range(vectors.shape[0]):\n",
    "    #print (rows)\n",
    "    linewords = np.where(vectors[rows]>0)\n",
    "    #sum(vectors[3]>0)\n",
    "    for lines in linewords:\n",
    "        for l in lines:\n",
    "            newtext += words[l]\n",
    "            counts[words[l]] += 1\n",
    "            \n",
    "print (newtext)\n",
    "print (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = Counter(counts).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['leslie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makewordcloud(lst):\n",
    "    fig = plt.figure(1,figsize=(100,100))\n",
    "    wordcloud = WordCloud(max_font_size=500, max_words=10000, background_color=\"white\").generate(str(lst).replace(\" \", '').replace(\"'\",\"\"))\n",
    "    #wordcloud = WordCloud(max_font_size=500, max_words=1000, background_color=\"white\").generate(str(topic_string).replace(\"'\",\"\").replace(\",\",\"\"))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.imshow(wordcloud)##\n",
    "    plt.show\n",
    "    img_time=str(time.time()).split('.')[0]\n",
    "    wordcloud.to_file('./img/%s.wordcloud.png'%(img_time))\n",
    "    w#ordcloud.to_file('./lst%d.png')\n",
    "makewordcloud(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in counts:\n",
    "    print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanct = data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(str):\n",
    "    counts = dict()\n",
    "    words = str.split()\n",
    "\n",
    "    for word in words:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "counts = word_count(sanct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_x = sorted(counts.items(), key=lambda kv: kv[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"cat\", \"pig\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[-1:-n-1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.sum(vectors, axis=0) / np.sum(vectors > 0, axis=0)\n",
    "print (\"top 10 by average tf-idf\")\n",
    "print (get_top_values(avg, 10, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.sum(vectors, axis=0)\n",
    "print (\"top 10 by total tf-idf\")\n",
    "print (get_top_values(total, 100, words))\n",
    "top_by_total = get_top_values(total, 50, words)\n",
    "makewordcloud(top_by_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in data.read():\n",
    "    print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
